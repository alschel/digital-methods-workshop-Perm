library(rvest)
library(tidyr)
?read_html
url <- "https://www.reformagkh.ru/myhouse?tid=2299765"
# Сохраним страницу в html
page <- read_html(url)
page
page %>%
html_nodes('td a') %>%  # используем сss селектор
html_text()
page %>%
html_nodes('.grid td:nth-child(2)') %>%
html_text()
url <- "https://www.reformagkh.ru/myhouse?sort=name&order=asc&page=1&limit=6800"
# Сохраним страницу в html
page <- read_html(url)
url <- "https://www.reformagkh.ru/myhouse?sort=name&order=asc&page=1&limit=6753"
# Сохраним страницу в html
page <- read_html(url)
library(tidyr)
res <- data.frame()
library(dplyr)
res <- data_frame()
res
res <- data_frame()
i <- 1
# for(i in 1:68){
url <- paste0("https://www.reformagkh.ru/myhouse?sort=name&order=asc&page=", i, "&limit=100")
# Save as html page
page <- read_html(url)
# Extrcat address data
page %>%
html_nodes('td a') %>%  # use css selector
html_text() -> address
# Extrcat year
page %>%
html_nodes('.grid td:nth-child(2)') %>%
html_text() -> year
url
# for(i in 1:68){
url <- paste0("https://www.reformagkh.ru/myhouse?tid=2299765&sort=name&order=asc&page=", i, "&limit=100")
url
page %>%
html_nodes('table[class="grid"] td a') %>%  # use css selector
html_text()
# for(i in 1:68){
url <- paste0("https://www.reformagkh.ru/myhouse?tid=2299765&sort=name&order=asc&page=", i, "&limit=100")
# Save as html page
page <- read_html(url)
page %>%
html_nodes('table[class="grid"] td a') %>%  # use css selector
html_text()
page %>%
html_nodes('table[class="grid"] > td a') %>%  # use css selector
html_text()
page %>%
html_nodes('td a') %>%  # use css selector
html_text()
page %>%
html_nodes('.hover') %>%
html_text()
page %>%
html_nodes('hover') %>%
html_text()
page %>%
html_nodes('td.hover') %>%
html_text()
page %>%
html_nodes('td:nth-child(2)') %>%
html_text()
page %>%
html_nodes('div[class=="grid"] > td:nth-child(2)') %>%
html_text()
page %>%
html_nodes('div[class="grid"] > td:nth-child(2)') %>%
html_text()
page %>%
html_nodes('.grid > td:nth-child(2)') %>%
html_text()
page %>%
html_nodes('.grid > tr:nth-child(2)') %>%
html_text()
page %>%
html_nodes('tr:nth-child(2)') %>%
html_text()
page %>%
html_nodes('tr > td:nth-child(2)') %>%
html_text()
page %>%
html_nodes('.sg_suggested') %>%
html_text()
page %>%
html_nodes('td.sg_suggested') %>%
html_text()
page %>%
html_nodes('td') %>%
html_text()
page %>%
html_nodes('.grid > td') %>%
html_text()
page %>%
html_nodes('div.grid > td') %>%
html_text()
page %>%
html_nodes('tr:nth-child(2)') %>%
html_text()
page %>%
html_nodes('td:nth-child(2)') %>%
html_text()
page %>%
html_nodes('.grid td:nth-child(2)') %>%
html_text()
res <- data_frame()
# for(i in 1:68){
url <- paste0("https://www.reformagkh.ru/myhouse?tid=2299765&sort=name&order=asc&page=", i, "&limit=100")
# Save as html page
page <- read_html(url)
# Extrcat address data
page %>%
html_nodes('td a') %>%  # use css selector
html_text() -> address
# Extrcat year
page %>%
html_nodes('.grid td:nth-child(2)') %>%
html_text() -> year
res <- bind_rows(res, bind_cols(address, year))
?bind_cols
?data_frame()
?data_frame
data_frame(address, year)
res <- bind_rows(res,data_frame(address, year))
res
res <- data_frame()
for(i in 1:3){
# Watch your step
print(i)
url <- paste0("https://www.reformagkh.ru/myhouse?tid=2299765&sort=name&order=asc&page=", i, "&limit=100")
# Save as html page
page <- read_html(url)
# Extrcat address data
page %>%
html_nodes('td a') %>%  # use css selector
html_text() -> address
# Extrcat year
page %>%
html_nodes('.grid td:nth-child(2)') %>%
html_text() -> year
res <- bind_rows(res,data_frame(address, year))
Sys.sleep(1)
}
View(res)
res <- data_frame()
for(i in 1:68){
# Watch your step
print(i)
url <- paste0("https://www.reformagkh.ru/myhouse?tid=2299765&sort=name&order=asc&page=", i, "&limit=100")
# Save as html page
page <- read_html(url)
# Extrcat address data
page %>%
html_nodes('td a') %>%  # use css selector
html_text() -> address
# Extrcat year
page %>%
html_nodes('.grid td:nth-child(2)') %>%
html_text() -> year
res <- bind_rows(res,data_frame(address, year))
Sys.sleep(1)
}
View(res)
res %>% stringr::str_replace_all("н.д.", NA)
res %>% stringr::str_replace_all("н.д.", NA_character_)
res %>% stringr::str_replace("н.д.", NA_character_)
res$year %>%
stringr::str_replace("н.д.", NA_character_)
library(stringr)
res %>%
mutate(year = str_replacel("н.д.", NA))
res %>%
mutate(year = str_replace("н.д.", NA))
# Change year type to integer
res %>%
mutate(year = str_replace("н.д.", NA_character_))
# Change year type to integer
res %>%
mutate(year = str_replace(year, "н.д.", NA))
# Change year type to integer
res %>%
mutate(year = str_replace(year, "н.д.", NA_character_))
# Change year type to integer
res %>%
mutate(year = str_replace(year, "н.д.", NA_character_) %>% as.integer())
# Replace "н.д." with NA and change year type to integer
res %>%
mutate(year = str_replace(year, "н.д.", NA_character_) %>% as.integer()) -> res
View(res)
# Let's take a look at the data
summarry(res)
# Let's take a look at the data
summary(res)
res %>% arrange(year) %>% head()
# Fix
res %>% filter(address = "г. Пермь, ул. Холмогорская, д. 4/2")
# Fix
res %>% filter(address == "г. Пермь, ул. Холмогорская, д. 4/2")
# Fix
res %>% filter(address == "г. Пермь, ул. Холмогорская, д. 4/2")[2]
# Fix
res %>% filter(address == "г. Пермь, ул. Холмогорская, д. 4/2")[,2]
# Fix
res %>% filter(address == "г. Пермь, ул. Холмогорская, д. 4/2") %>% .[,2]
res[res$address == "г. Пермь, ул. Холмогорская, д. 4/2", 2]
# Fix
res[res$address == "г. Пермь, ул. Холмогорская, д. 4/2", 2] <- 1975
res %>% arrange(year) %>% head()
res %>% filter(year > 1800)
res %>% filter(year > 1800 && !is.na(year))
res %>% filter(year > 1800 || !is.na(year))
res %>% filter(year > 1800 | !is.na(year))
# Let's take a look at the data
summary(res) # there are some stranges
res %>% arrange(year) %>% head()
res[res$address == "г. Пермь, ул. Маяковского, д. 36", 2] <- 1955
# Remove all na rows
res %>% filter(!is.na(year)) -> res
View(res)
res %>% ggplot(aes(year))+
geom_density()
library(ggplot2)
res %>% ggplot(aes(year))+
geom_density()
res %>% ggplot(aes(year))+
geom_boxplot()
res %>% ggplot(aes(year))+
geom_histogram()
res %>% arrange(year) %>% head()
res[res$address == "г. Пермь, ул. Серпуховская, д. 15", 2] <- 1955
# Remove all na rows
res %>% filter(!is.na(year)) -> res
res %>% ggplot(aes(year))+
geom_histogram()
library(RColorBrewer)
res %>% ggplot(aes(year))+
geom_histogram(fill = brewer.pal(5, "YlGn"))
res %>% ggplot(aes(year))+
geom_histogram()+
theme_dark()
res %>% ggplot(aes(year))+
geom_histogram()+
theme_classic()
res %>% ggplot(aes(year))+
geom_histogram()
# Distirbution
res %>% ggplot(aes(year))+
geom_histogram(binwidth = 2)
?labs
# Distirbution
res %>% ggplot(aes(year))+
geom_histogram(binwidth = 2)+
labs(y = "Number of buildings", y = "Year")
# Distirbution
res %>% ggplot(aes(year))+
geom_histogram(binwidth = 2)+
labs(y = "Number of buildings", x = "Year")
# Distirbution
res %>% ggplot(aes(year))+
geom_histogram(aes(fill = brewer.pal(5, "YlGn")),binwidth = 2)+
labs(y = "Number of buildings", x = "Year")
brewer.pal(5, "YlGn")
brewer.pal(5, "YlGn") * 5
# Distirbution
res %>% ggplot(aes(year))+
geom_histogram(aes(), binwidth = 2)+
labs(y = "Number of buildings", x = "Year")
brewer.pal(5, "YlG
# Check the distirbution
res %>% ggplot(aes(year))+
geom_histogram(aes(), binwidth = 2)+
labs(y = "Number of buildings", x = "Year")+
scale_x_continuous(breaks = seq(1850, 2017, 50))
# Check the distirbution
res %>% ggplot(aes(year))+
geom_histogram(aes(), binwidth = 2)+
labs(y = "Number of buildings", x = "Year")+
scale_x_continuous(breaks = seq(1850, 2017, 20))
# Check the distirbution
res %>% ggplot(aes(year))+
geom_histogram(aes(), binwidth = 2)+
labs(y = "Number of buildings", x = "Year")+
scale_x_continuous(breaks = seq(1850, 2017, 25))
# Check the distirbution
res %>% ggplot(aes(year))+
geom_histogram(aes(), binwidth = 2)+
labs(y = "Number of buildings", x = "Year")+
scale_x_continuous(breaks = seq(1850, 2017, 10))
perm_biuldings <- data_frame()
View(res)
perm_buildings <- data_frame()
rm(perm_biuldings)
n <- 56
# Specifying the url for desired website to be scrapped
url <- paste0("https://geocode-maps.yandex.ru/1.x/?geocode=", res[n, 1])
url
# Reading the HTML code from the website
page <- read_html(url)
# Parcing with css selector number of found results and their kind
page %>% html_nodes('found') %>% html_text() %>% as.integer(.) -> found
page %>% html_nodes('precision') %>% html_text() -> precision
if (found >= 1 && precision[1] == "exact") {
coords <- webpage %>% html_nodes('pos') %>% html_text() %>% .[1]
res <- bind_cols(res[n,], coords)
} else {
temp_table <- cbind(res[n,], coords = NA)
}
if (found >= 1 && precision[1] == "exact") {
coords <- page %>% html_nodes('pos') %>% html_text() %>% .[1]
res <- bind_cols(res[n,], coords)
} else {
temp_table <- cbind(res[n,], coords = NA)
}
res[n,]
bind_cols(res[n,], coords = coords)
if (found >= 1 && precision[1] == "exact") {
coords <- page %>% html_nodes('pos') %>% html_text() %>% .[1]
temp_table <- bind_cols(res[n,], coords = coords)
} else {
temp_table <- cbind(res[n,], coords = NA)
}
temp_table
perm_buildings <- bind_rows(perm_buildings, temp_table)
perm_buildings
perm_buildings <- data_frame()
for (n in 123:135) {
print(n)
# Specifying the url for desired website to be scrapped
url <- paste0("https://geocode-maps.yandex.ru/1.x/?geocode=", res[n, 1])
# Reading the HTML code from the website
page <- read_html(url)
# Parcing with css selector number of found results and their kind
page %>% html_nodes('found') %>% html_text() %>% as.integer(.) -> found
page %>% html_nodes('precision') %>% html_text() -> precision
if (found >= 1 && precision[1] == "exact") {
coords <- page %>% html_nodes('pos') %>% html_text() %>% .[1]
temp_table <- bind_cols(res[n,], coords = coords)
} else {
temp_table <- cbind(res[n,], coords = NA)
}
perm_buildings <- bind_rows(perm_buildings, temp_table)
Sys.sleep(1)
}
View(perm_buildings)
View(perm_buildings)
# Разобьем строку координат в отдельные столбцы Lat и Lon
perm_buildings <- separate(perm_buildings, # таблица
coords, # столбец для деления
into = c("LonY", "LatY"), # названия новых столбцов
sep = " ", # основание для разделения
remove = TRUE, # удаляем столбец coords
convert = TRUE) # применяем к новым значениям функцию type.convert (автоматически определяет тип данных)
View(perm_buildings)
separate
?separate
perm_buildings <- data_frame()
# Цикл запросов к геокодеру Яндекс
for (n in 1:nrow(res)) {
# Watch the steps
print(n)
# Specifying the url for desired website to be scrapped
url <- paste0("https://geocode-maps.yandex.ru/1.x/?geocode=", res[n, 1])
# Reading the HTML code from the website
page <- read_html(url)
# Parcing with css selector number of found results and their precision
page %>% html_nodes('found') %>% html_text() %>% as.integer(.) -> found
page %>% html_nodes('precision') %>% html_text() -> precision
# If there are results and precision is exact, we add coords to our table
if (found >= 1 && precision[1] == "exact") {
coords <- page %>% html_nodes('pos') %>% html_text() %>% .[1]
temp_table <- bind_cols(res[n,], coords = coords)
} else {
temp_table <- cbind(res[n,], coords = NA)
}
perm_buildings <- bind_rows(perm_buildings, temp_table)
# Sleep
Sys.sleep(1)
}
View(perm_buildings)
# Разобьем строку координат в отдельные столбцы Lat и Lon
perm_buildings_geocoded <- separate(perm_buildings,
coords, # столбец для деления
into = c("Lon", "Lat"), # названия новых столбцов
sep = " ", # основание для разделения
remove = TRUE, # удаляем столбец coords
convert = TRUE) # применяем к новым значениям функцию type.convert (автоматически определяет тип данных)
library(readr)
write_csv(perm_buildings_geocoded, "perm_buildings_geocoded.csv")
write_csv(perm_buildings_geocoded, "data/perm_buildings_geocoded.csv")
View(perm_buildings_geocoded)
perm_buildings_geocoded %>% summary()
# уберем na
perm_buildings_geocoded %>%
filter(!is.na(Lon))
# уберем na
perm_buildings_geocoded %>%
filter(!is.na(Lon)) -> perm_buildings_geocoded
perm_buildings_geocoded
# Save the results in csv file
write_csv(perm_buildings_geocoded, "data/perm_buildings_geocoded.csv")
library(rvest)
library(dplyr)
library(stringr)
library(ggplot2)
library(RColorBrewer)
library(readr)
# Check the distirbution
res %>% ggplot(aes(year))+
geom_histogram(aes(), binwidth = 2)+
labs(y = "Number of buildings", x = "Year")+
scale_x_continuous(breaks = seq(1850, 2017, 10))
library(viridis)
viridis_pal()
show_col(viridis_pal()(10))
viridis_pal()(10)
viridis_pal()(11)
viridis_pal()(11) %>% reversed()
rev(viridis_pal()(11))
viridis(option = "A", n = 11)
library(sp)
library(rgdal)
# we downloaded OSM polygon data
points <- readOGR("data/perm_buildings.geojson")
plot(points)
points
points
str(points)
polygons <- readOGR("data/export-4.geojson")
polygons <- readOGR("data/OSM-data.geojson")
?over
perm_buildings_geocoded
years <- over(polygons, points[,"year"])
years
polygons@data$year <- years
!is.na(polygons@data$year)
# Filter nonNA
perm_buildings_osm <- polygons[!is.na(polygons@data$year),]
!is.na(polygons@data$year),
polygons[!is.na(polygons@data$year)]
!is.na(polygons$year)
# Filter nonNA
perm_buildings_osm <- polygons[!is.na(polygons$year),]
polygons[!is.na(polygons$year),]
polygons[polygons$year>1950,]
polygons[is.na(polygons@data$year), ]
subset(polygons, !is.na(polygons@data$year))
polygons
View(polygons)
View(years)
over(polygons, points[,"year"])
years <-
polygons@data$year <-
# Remove buildings with NA year
perm_buildings_osm_year <- polygons[is.na(polygons@data$year), ]
years <- over(polygons, points[,"year"])
polygons@data$year <- years$year
# Remove buildings with NA year
perm_buildings_osm_year <- polygons[!is.na(polygons@data$year), ]
plot(perm_buildings_osm_year)
writeOGR(perm_buildings_osm_year, "data/perm_buildings_osm-year.geojson", driver = "GeoJSON")
writeOGR(perm_buildings_osm_year, "data/perm_buildings_osm-year.geojson", layer = "perm_buildings_osm-year.geojson", driver = "GeoJSON")
points_data <- over(polygons, points[,c("address", "year")])
rm(years)
polygons@data$year <- points_data$year
polygons@data$address <- points_data$address
# Remove buildings with NA year
perm_buildings_osm_year <- polygons[!is.na(polygons@data$year), ]
writeOGR(perm_buildings_osm_year, "data/perm_buildings_osm-year.geojson",
layer = "perm_buildings_osm-year.geojson", driver = "GeoJSON", overwrite_layer = T)
